{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3809ef-09d5-4119-ad01-4c535223d59a",
   "metadata": {},
   "source": [
    "Q3.\n",
    "ans:-\n",
    "Experimentation with different hyperparameters such as learning rate, number of trees, and tree depth can be done by modifying the constructor arguments of the GradientBoostingRegressor class and observing the resulting performance metrics. Alternatively, you can use grid search or random search techniques to find the best hyperparameters automatically.\n",
    "\n",
    "Q4.\n",
    "ans:-In Gradient Boosting, a weak learner refers to a simple model, often a decision tree with limited depth, that performs slightly better than random guessing on a given dataset. Weak learners are typically combined to form a strong predictive model through boosting.\n",
    "\n",
    "Q5.\n",
    "ans:-The intuition behind the Gradient Boosting algorithm is to iteratively improve upon an existing model by fitting new models to the residuals or errors made by the previous model. Each new model focuses on capturing the remaining errors of the ensemble, gradually reducing the overall error and improving predictive performance.\n",
    "\n",
    "Q6\n",
    "ans:-. Gradient Boosting algorithm builds an ensemble of weak learners by sequentially adding models to the ensemble, with each new model trained to correct the errors made by the existing ensemble. The final prediction is obtained by aggregating the predictions of all weak learners, often weighted by a learning rate parameter.\n",
    "\n",
    "Q7.\n",
    "ans:-The steps involved in constructing the mathematical intuition of Gradient Boosting algorithm include initializing the predictions, calculating the residuals or errors, training a weak learner to predict these residuals, and updating the predictions by adding the predictions of the weak learner multiplied by a learning rate. These steps are repeated iteratively until the desired number of weak learners is reached or until convergence is achieved.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
